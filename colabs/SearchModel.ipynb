{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SearchModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "X_pR5rM-_NHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kaggle Dataset**"
      ],
      "metadata": {
        "id": "qKwjnvzMD5G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "wmQ7EhYWD2jZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8782cf-e69a-4c54-c8e2-5ebd32c5b534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od"
      ],
      "metadata": {
        "id": "S6Ctf8fCD8ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для следующей ячейки потребуются данные из Kaggle аккаунта:\n",
        "\n",
        "You Profile -> Account -> Create New API Token"
      ],
      "metadata": {
        "id": "nFjL1D9w8WPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/jessicali9530/stl10\")"
      ],
      "metadata": {
        "id": "e5cMBwZFEBQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Work with SearchModel"
      ],
      "metadata": {
        "id": "zs1P0jKsfXFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ruclip==0.0.1 > /dev/null"
      ],
      "metadata": {
        "id": "k1GzMZZprsrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# from faiss import Indexer\n",
        "\n",
        "\n",
        "class DummyIndexer():\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Creates an empty index object\n",
        "        \"\"\"\n",
        "        self.index = None\n",
        "\n",
        "    def add(self, embs: np.ndarray):\n",
        "        \"\"\"\n",
        "        Adds new embeddings embs in empty or existing index\n",
        "        :param embs:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if self.index is None:\n",
        "            self.index = embs\n",
        "        else:\n",
        "            self.index = np.append(self.index, embs, axis=0)\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Not sure if this one is necessary here, left for compatibility with abstract class Indexer\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def find(self, query: np.ndarray, topn: int) -> (np.ndarray, np.ndarray):\n",
        "        \"\"\"\n",
        "        Returns topn entries closest to the query vector\n",
        "        :param query:\n",
        "        :param topn:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        similarities = (self.index @ query.squeeze())\n",
        "        best_photo_idx = (-similarities).argsort()\n",
        "        D, I = similarities[best_photo_idx[:topn]], best_photo_idx[:topn]\n",
        "        return D, I\n",
        "\n",
        "    def save(self, file: str):\n",
        "        \"\"\"\n",
        "        Saves data to npy file\n",
        "        :param file:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        np.save(file, self.index)\n",
        "\n",
        "    def load(self, file: str):\n",
        "        \"\"\"\n",
        "        Loads data from npy file\n",
        "        :param file:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.index = np.load(file)"
      ],
      "metadata": {
        "id": "4_tc1BeztwP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import abc\n",
        "\n",
        "import torch\n",
        "import ruclip\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from numbers import Number\n",
        "from typing import List\n",
        "\n",
        "class Embedder(abc.ABC):\n",
        "    @abc.abstractmethod\n",
        "    def encode_text(self, text):\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def encode_imgs(self, imgs):\n",
        "        pass\n",
        "\n",
        "    def cos(self, emb1: np.ndarray, emb2: np.ndarray) -> Number:\n",
        "        \"\"\"\n",
        "        Returns cos similarity between two embeddings\n",
        "        :param emb1: 1D tensor\n",
        "        :param emb2: 1D tensor\n",
        "        :return: cos similarity (Number)\n",
        "        \"\"\"\n",
        "        emb1, emb2 = emb1.squeeze(), emb2.squeeze() # convert (1, N) arrays to (N,)\n",
        "        return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
        "\n",
        "\n",
        "class EmbedderRuCLIP(Embedder):\n",
        "    def __init__(self, ruclip_model_name='ruclip-vit-base-patch32-384',\n",
        "             device='cpu', templates = ['{}', 'это {}', 'на картинке {}']):\n",
        "        \"\"\"\n",
        "        :param ruclip_model_name:\n",
        "        :param device:\n",
        "        :param templates:\n",
        "        \"\"\"\n",
        "        clip, processor = ruclip.load(ruclip_model_name)\n",
        "        self.predictor = ruclip.Predictor(clip, processor, device, bs=8, templates=templates)\n",
        "\n",
        "    def _tonumpy(self, tensor: torch.Tensor) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Detaches tensor from GPU and converts it to numpy array\n",
        "        :return: numpy array\n",
        "        \"\"\"\n",
        "        return tensor.cpu().detach().numpy()\n",
        "\n",
        "    def encode_text(self, text: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Returns text latent of the text input\n",
        "        :param text:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        classes = [text, ]\n",
        "        with torch.no_grad():\n",
        "            text_latent = self.predictor.get_text_latents(classes)\n",
        "        return self._tonumpy(text_latent)\n",
        "\n",
        "    def encode_imgs(self, pil_imgs: List[Image.Image]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Returns image latents of a image batch\n",
        "        :param pil_imgs: list of PIL images\n",
        "        :return img_latents: numpy array of img latents\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            img_latents = self.predictor.get_image_latents(pil_imgs)\n",
        "        return self._tonumpy(img_latents)"
      ],
      "metadata": {
        "id": "32X9OSv1pxZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from PIL import Image\n",
        "from typing import List\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class SearchModel():\n",
        "    def __init__(self, embedder, indexer):\n",
        "        self.embedder = embedder\n",
        "        self.indexer = indexer\n",
        "        self.indexed_imgs_path = [] # array with indexed embeddings\n",
        "        self.images_dir = None\n",
        "        self.imgs_path = None       # array for temp embeddings storage\n",
        "        self.features_path = None\n",
        "\n",
        "    def load_imgs(self, path: str, prefix: str):\n",
        "        \"\"\"\n",
        "        Returns a list of names images in a given path\n",
        "        :param path:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.images_dir = path\n",
        "        photos_path = Path(self.images_dir)\n",
        "        features_dir = str(photos_path.parents[0]) + '/features/' + prefix\n",
        "        self.features_path = Path(features_dir)\n",
        "        self.imgs_path = list(photos_path.glob(\"*.*\"))\n",
        "\n",
        "        try:\n",
        "          os.mkdir(str(photos_path.parents[0]) + '/features')\n",
        "          os.mkdir(features_dir)\n",
        "        except:\n",
        "          self.indexed_imgs_path = list(pd.read_csv(f\"{self.features_path}/photo_ids.csv\")['photo_id'])\n",
        "\n",
        "\n",
        "    def load_img_urls(self):\n",
        "        \"\"\"\n",
        "        In case we want to load imgs from a list of url\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def add_photo_path(self, name):\n",
        "        return f'{self.images_dir}/{name}.png'\n",
        "\n",
        "    def save_embs(self) -> None:\n",
        "        \"\"\"\n",
        "        Extracts image embeddings from embedder and adds them to indexer\n",
        "        :param pil_imgs:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.indexed_imgs_path.extend(self.imgs_path)\n",
        "\n",
        "        if(len(self.imgs_path) >= 512):\n",
        "          batch_size = 512\n",
        "        else:\n",
        "          batch_size = len(self.imgs_path)\n",
        "\n",
        "        # Compute how many batches are needed\n",
        "        batches = math.ceil(len(self.imgs_path) / batch_size)\n",
        "\n",
        "        # Process each batch\n",
        "        for i in range(batches):\n",
        "          print(f\"Processing batch {i+1}/{batches}\")\n",
        "\n",
        "          batch_ids_path = self.features_path / f\"{i:010d}.csv\"\n",
        "          batch_features_path = self.features_path / f\"{i:010d}.npy\"\n",
        "    \n",
        "          # Only do the processing if the batch wasn't processed yet\n",
        "          if not batch_features_path.exists():\n",
        "            try:\n",
        "              # Select the photos for the current batch\n",
        "              batch_files = self.imgs_path[i*batch_size : min(len(self.imgs_path), (i+1)*batch_size)]\n",
        "              pil_batch = [Image.open(photo_file) for photo_file in batch_files]\n",
        "\n",
        "              # Compute the features and save to a numpy file\n",
        "              batch_features = self.embedder.encode_imgs(pil_batch)\n",
        "              np.save(batch_features_path, batch_features)\n",
        "\n",
        "              # Save the photo IDs to a CSV file\n",
        "              photo_ids = [photo_file.name.split(\".\")[0] for photo_file in batch_files]\n",
        "              photo_ids_data = pd.DataFrame(photo_ids, columns=['photo_id'])\n",
        "              photo_ids_data.to_csv(batch_ids_path, index=False)\n",
        "            except:\n",
        "              # Catch problems with the processing to make the process more robust\n",
        "              print(f'Problem with batch {i}')\n",
        "\n",
        "        # Load all numpy files\n",
        "        features_list = [np.load(features_file) for features_file in sorted(self.features_path.glob(\"*.npy\"))]\n",
        "\n",
        "        # Concatenate the features and store in a merged file\n",
        "        features = np.concatenate(features_list)\n",
        "        np.save(self.features_path / \"features.npy\", features)\n",
        "\n",
        "        # Load all the photo IDs\n",
        "        photo_ids = pd.concat([pd.read_csv(ids_file) for ids_file in sorted(self.features_path.glob(\"*.csv\"))])\n",
        "        photo_ids = photo_ids[\"photo_id\"].apply(self.add_photo_path)\n",
        "        photo_ids.to_csv(self.features_path / \"photo_ids.csv\", index=False)\n",
        "        \n",
        "        for file in glob.glob('{}/0*.*'.format(self.features_path)):\n",
        "          os.remove(file)\n",
        "        \n",
        "        self.indexer.add(embs=features)    \n",
        "    \n",
        "    def get_k_imgs(self, emb: np.ndarray, k: int):\n",
        "        \"\"\"\n",
        "        Returns k indices of nearest image embeddings and respective distances for a given embedding emb\n",
        "        :param emb:\n",
        "        :param k:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        distances, indices = self.indexer.find(emb, k)\n",
        "        return distances, np.array(self.indexed_imgs_path)[indices]"
      ],
      "metadata": {
        "id": "Jezr0YaofYGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для создание индексов в Colab"
      ],
      "metadata": {
        "id": "lGAkHZDWtPt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = SearchModel(EmbedderRuCLIP(device='cuda'), DummyIndexer())"
      ],
      "metadata": {
        "id": "_n_-kvVNse9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prefix зависит от того, какую модель вы подали в SearchModel"
      ],
      "metadata": {
        "id": "V6y68GyLzHFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.load_imgs('/content/stl10/train_images','RuCLIP')\n",
        "test_model.save_embs()"
      ],
      "metadata": {
        "id": "3ehUwO7Wt5Oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5609a0-f0db-4f7a-873e-be07bf007710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 48.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 48.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 48.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 49.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 49.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 49.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 49.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 49.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "512it [00:10, 49.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "392it [00:08, 47.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = test_model.embedder.encode_text(text=\"Обезьяна играет с мячиком\")\n",
        "test_model.get_k_imgs(query, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqLTpwdsWjT8",
        "outputId": "a1e99755-438a-4782-fb49-7a211938b213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.53042364, 0.4278646 , 0.41783807], dtype=float32),\n",
              " array([PosixPath('/content/stl10/train_images/train_image_png_1815.png'),\n",
              "        PosixPath('/content/stl10/train_images/train_image_png_2566.png'),\n",
              "        PosixPath('/content/stl10/train_images/train_image_png_2900.png')],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для работы в Streamlit"
      ],
      "metadata": {
        "id": "WZ1i3v2VtXNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_streamlit = SearchModel(EmbedderRuCLIP(device='cpu'), DummyIndexer())"
      ],
      "metadata": {
        "id": "CJ3s9-CltdT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'/content/stl10/train_images' - Путь к самим изображениям\n",
        "\n",
        "'/content/stl10/features' - Путь, где находится csv и npy файл\n",
        "\n",
        "На сервере в папке датасета нужно будет создать папку \"features\" в ней \"CLIP\"/\"RuCLIP\" или скачивать всё с Colab и переносить в нужный путь\n",
        "\n",
        "Выбор prefix зависит от подаваемого текста или же от того, на какой модели пользователь хочет получить результат, в данный момент поддерживаются \"CLIP\" и \"RuCLIP\"\n"
      ],
      "metadata": {
        "id": "072xH1FiuJaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_streamlit.load_imgs('/content/stl10/train_images','RuCLIP')"
      ],
      "metadata": {
        "id": "CedSpkl3tgpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_streamlit.indexer.load(str(test_streamlit.features_path) + '/features.npy')"
      ],
      "metadata": {
        "id": "ZGBskh7atl0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = test_streamlit.embedder.encode_text(text=\"Обезьяна играет с мячиком\")\n",
        "test_streamlit.get_k_imgs(query, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc466ed-9048-4579-b93a-2bd6325ea816",
        "id": "0RZ-PitLto8N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 469 ms, sys: 5.93 ms, total: 475 ms\n",
            "Wall time: 469 ms\n"
          ]
        }
      ]
    }
  ]
}